# 성능 최적화 리포트

## 테스트 환경

| 항목 | 상세 |
|------|------|
| 데이터 규모 | 100만 건 카드 거래 데이터 |
| 파일 크기 (CSV) | 약 120 MB |
| EMR 클러스터 | m5.xlarge 3대 (Master 1, Core 2) |
| Spark 버전 | 3.5 |
| 압축 코덱 | Snappy |

---

## 1. CSV vs Parquet 비교

### 결과

| 항목 | CSV | Parquet | 개선률 |
|------|-----|---------|--------|
| 파일 크기 | ~120 MB | ~30 MB | 75% 절감 |
| 읽기 시간 | ~8.5초 | ~2.1초 | 75% 단축 |
| 스키마 추론 | 필요 (오버헤드) | 내장 | - |
| 컬럼 선택 읽기 | 불가 (전체 읽기) | 가능 (Predicate Pushdown) | - |

### 분석
- Parquet은 컬럼 기반 포맷으로, 특정 컬럼만 읽을 때 CSV 대비 큰 성능 이점
- Snappy 압축으로 저장 공간 75% 절감
- 실무에서는 원본 CSV 수신 후 즉시 Parquet 변환하여 후속 처리에 활용 권장

---

## 2. 파티셔닝 전략 비교

### 결과 (특정일 1일치 조회 기준)

| 전략 | 쓰기 시간 | 조회 시간 | 개선률 |
|------|----------|----------|--------|
| 파티션 없음 | ~3.2초 | ~4.8초 | 기준 |
| 날짜 파티션 (txn_date) | ~12.5초 | ~0.8초 | 83% 단축 |
| 연/월 파티션 (year, month) | ~5.1초 | ~1.5초 | 69% 단축 |

### 분석
- 날짜 파티셔닝은 쓰기 시간이 증가하지만 조회 시간이 큰 폭 단축
- 파티션이 너무 세분화되면 (365개 날짜 파티션) 소규모 파일 문제 발생 가능
- 실무 권장: 연/월 파티션으로 적절한 균형 유지
  - 분기별 배치 조회에 최적화
  - 파티션 수 관리 용이 (12개/년)

---

## 3. 캐싱 효과

### 결과 (동일 집계 쿼리 반복 실행)

| 실행 | 캐싱 없음 | 캐싱 적용 | 개선률 |
|------|----------|----------|--------|
| 1회차 | ~6.2초 | ~7.1초 (캐싱 포함) | - |
| 2회차 | ~5.8초 | ~0.9초 | 84% 단축 |
| 3회차 | ~5.9초 | ~0.8초 | 86% 단축 |

### 분석
- 1회차는 캐싱 오버헤드로 오히려 느림
- 2회차부터 메모리에서 직접 읽어 큰 폭 성능 향상
- 동일 데이터에 여러 분석 쿼리를 실행하는 패턴에서 효과적
- 주의: 메모리 부족 시 디스크 Spill 발생 -> 오히려 성능 저하 가능

---

## 4. 브로드캐스트 조인 vs 일반 조인

### 결과 (카테고리 마스터 테이블 조인)

| 조인 방식 | 소요 시간 | 셔플 발생 |
|----------|----------|----------|
| 일반 조인 (Sort Merge) | ~4.5초 | 있음 |
| 브로드캐스트 조인 | ~2.1초 | 없음 |

### 분석
- 소규모 테이블 (수백~수만 건)과 대규모 테이블 조인 시 브로드캐스트 효과적
- 브로드캐스트 조인은 소규모 테이블을 모든 Executor에 복제하여 셔플 제거
- 실무에서 코드 마스터, 카테고리 분류표 등과 조인할 때 활용
- 기본 임계값: 10MB (spark.sql.autoBroadcastJoinThreshold)

---

## 5. 리파티셔닝 전략

### 결과 (카테고리별 집계 쿼리)

| 파티션 수 | 소요 시간 | 비고 |
|----------|----------|------|
| 1 | ~8.2초 | 단일 스레드, 병렬성 없음 |
| 4 | ~3.5초 | CPU 코어 수 이하 |
| 8 | ~2.8초 | CPU 코어 수 근접 |
| 16 | ~2.5초 | 적정 |
| 50 | ~2.9초 | 파티션 오버헤드 증가 |
| 200 | ~3.8초 | 과도한 파티션 |

### 분석
- 파티션 수는 클러스터 총 코어 수의 2~3배가 적정
  - 3대 x 4 vCPU = 12 코어 -> 24~36개 적정
- 파티션이 너무 적으면 병렬성 부족
- 파티션이 너무 많으면 태스크 스케줄링 오버헤드 증가
- Spark 3.x AQE(Adaptive Query Execution) 활성화로 자동 조정 권장

---

## 종합 최적화 권장사항

### 저장 포맷
1. 원본 CSV는 수신 후 즉시 Parquet으로 변환
2. Snappy 압축 적용 (압축률과 속도의 균형)

### 파티셔닝
1. 시계열 데이터는 연/월 파티션 적용
2. 자주 필터링하는 컬럼을 파티션 키로 선택
3. 파티션 수가 과도하지 않도록 관리 (소규모 파일 문제 방지)

### 메모리 관리
1. 반복 사용 데이터는 cache() 적용
2. 사용 완료 후 unpersist()로 메모리 해제
3. 메모리 부족 시 MEMORY_AND_DISK 레벨 고려

### 조인 최적화
1. 소규모 테이블은 broadcast() 힌트 사용
2. 대규모 테이블 간 조인은 조인 키로 사전 파티셔닝

### 클러스터 설정
1. Dynamic Allocation 활성화 (워크로드에 맞게 Executor 자동 조정)
2. AQE 활성화 (Spark 3.x)
3. Shuffle Partition 수는 워크로드에 맞게 조정 (기본 200은 대부분 과도)
